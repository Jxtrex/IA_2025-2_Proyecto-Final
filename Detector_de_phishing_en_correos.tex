\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{soul}

% Cambios a nombres
\renewcommand{\abstractname}{Resumen}
\renewcommand{\IEEEkeywordsname}{Palabras clave}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Detector de phishing en correos electrónicos}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{5\textsuperscript{th} Juan de Dios Lerzundi}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
juan.lerzundi.r@uni.pe}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle

\begin{abstract}
El phishing por correo electrónico sigue siendo una de las principales amenazas a la seguridad informática. En este trabajo se presenta un sistema de detección de correos electrónicos de phishing basado en técnicas de aprendizaje supervisado y procesamiento de lenguaje natural. Partiendo de un dataset preprocesado, se compararon dos clasificadores clásicos: Multinomial Naive Bayes y Random Forest. El preprocesamiento incluyó limpieza, normalización, tokenización, eliminación de stopwords, lematización y vectorización mediante TF-IDF. La evaluación se realizó mediante validación cruzada y mediciones de precisión, recall, F1-score, ROC-AUC y PR-AUC. Los resultados (placeholders) muestran que Random Forest supera a Naive Bayes en F1 y recall, sugiriendo que los modelos de conjunto aprovechan mejores interacciones entre características textuales. Se discuten implicancias, limitaciones y direcciones futuras, incluyendo el uso de embeddings contextualizados (p. ej. BERT) y la incorporación de metadatos del correo (remitente, dominio, encabezados).
\end{abstract}

\begin{IEEEkeywords}
phishing, detección de spam, procesamiento de lenguaje natural, Random Forest, Naive Bayes, TF-IDF, clasificación supervisada
\end{IEEEkeywords}
%========================
\section{Introducción}

\textbf{Contexto y Motivación}\\
El correo electrónico es una herramienta de comunicación masiva usada en ámbitos personales, académicos y empresariales. Su popularidad la convierte en un vector atractivo para ataques de ingeniería social y fraude digital. El phishing (y su forma dirigida spear-phishing) busca engañar al usuario para obtener credenciales o información sensible, provocando pérdidas económicas, robo de identidad y compromiso de sistemas (Fette, Sadeh, \& Tomasic, 2007).

\textbf{Importancia del Problema}\\
Los filtros tradicionales basados en listas negras o reglas simples no son suficientemente robustos frente a mensajes que imitan lenguaje legítimo o utilizan pequeñas variaciones en dominios. Por ello, la aplicación de técnicas de IA y procesamiento de lenguaje natural (PLN) para analizar contenido y metadatos del correo es una línea prometedora para mejorar la detección (Abu-Nimeh et al., 2007).

\textbf{Objetivos del Proyecto}\\
Desarrollar y evaluar un prototipo de detector de phishing en correos electrónicos utilizando técnicas de Machine Learning y PLN, comparando Naive Bayes y Random Forest sobre un dataset preprocesado, con el objetivo de maximizar la detección (recall) y mantener una F1 alta.

\textbf{Restricciones}\\
\begin{itemize}
    \item El proyecto se centra en la detección de phishing general (no spear-phishing dirigido).
    \item Se parte de un dataset ya preprocesado (el informe detalla el proceso de preprocesamiento realizado).
\end{itemize}
%========================
\section{Metodología}

El sistema consta de los siguientes módulos:

\subsection{Flujo General}
\begin{enumerate}
    \item \text{Preprocesamiento:} normalización y limpieza del texto del correo (remoción de HTML, URLs, tokens no alfabéticos), reemplazo de direcciones y números por tokens especiales, minúsculas, eliminación de stopwords, lematización/stemming.
    \item \textbf{Extracción de características:} representación mediante TF-IDF (n-grams unigrama y bigrama), inclusión opcional de features booleanos (presencia de URL, cantidad de enlaces, uso de palabras claves sospechosas) y metadatos (dominio remitente, encabezados).
    \item \textbf{Partición de datos y balanceo:} división Train/Test (p. ej. 80/20) y validación cruzada (5-fold). En presencia de desbalance, aplicación de técnicas como SMOTE o submuestreo estratificado.
    \item \textbf{Entrenamiento:} entrenamiento de Multinomial Naive Bayes y RandomForestClassifier (scikit-learn).
    \item \textbf{Evaluación:} cálculo de accuracy, precision, recall, F1, ROC-AUC y PR-AUC; generación de matriz de confusión y análisis de importancia de variables (Random Forest).
    \item \textbf{Análisis y despliegue:} análisis de casos erróneos, propuestas de mejora y diseño de prototipo para integración en pipeline de correo.
    \item \textbf{}
    \item \textbf{}
\end{enumerate}

\subsection{Preprocesamiento}

\begin{enumerate}
    \item \textbf{Limpieza:} eliminar etiquetas HTML, normalizar saltos de línea, eliminar caracteres no ASCII si procede.
    \item \textbf{Normalización:} pasar a minúsculas, normalizar acentos.
    \item \textbf{Tokens especiales:} reemplazar URLs por \texttt{<URL>}, direcciones de email por \texttt{<EMAIL>} y números por \texttt{<NUM>}.
    \item \textbf{Tokenización:} separación en tokens — se consideraron n-grams (1,2).
    \item \textbf{Stopwords \& Lematización:} remover palabras funcionales y lematizar para reducir variabilidad morfológica.
    \item \textbf{Vectorización:} TF-IDF con límite de vocabulario (p. ej. max\_features=20,000), ngram\_range=(1,2), y sublinear\_tf=True.
\end{enumerate}

\subsection{Modelos}

\begin{itemize}
    \item \textbf{Multinomial Naive Bayes:} \hl{sklearn.naive\_bayes.MultinomialNB(alpha=1.0)} como baseline para datos textuales.
    \item \textbf{Random Forest:} \hl{sklearn.ensemble.RandomForestClassifier} \hl{(n\_estimators=200, max\_depth=None, n\_jobs=-1, random\_state=42)} usado para capturar interacciones entre tokens y es robusto a features ruidosos.
    \item \textbf{Validación:} 5-fold cross-validation y evaluación sobre test holdout (80/20). Se reportan métricas promedio y desviación estándar.
\end{itemize}

\subsection{Métricas de evaluación}

\begin{itemize}
    \item \textbf{Precision, Recall, F1-score:} para la clase positiva (phishing).
    \item \textbf{ROC-AUC y PR-AUC:} dado que la clase positiva puede ser minoritaria, PR-AUC es útil para valorar el rendimiento en detección.
    \item \textbf{Matriz de confusión:} análisis de falsos positivos y falsos negativos (importante por coste distinto de ambos errores).
\end{itemize}
%========================
\section{Resultados}

\subsection{Tabla comparativa de métricas}

\blindtext

\subsection{Matrices de confusión}

\blindtext

\subsection{Figuras}
%========================
\section{Discusión}

\subsection{Comparación de Modelos}

\begin{itemize}
    \item \blindtext
\end{itemize}

\subsection{Preprocesamiento}

\blindtext

\subsection{Limitaciones}

\blindtext

%========================
\section{Conclusiones}

\subsection{Conclusiones Principales}

\blindtext

\subsection{Trabajo a Futuro}

\blindtext
%========================
\begin{thebibliography}{00}
\bibitem{AbuNimeh2007}
Abu-Nimeh, S., Nappa, D., Wang, X., \& Nair, S. (2007).
A comparison of machine learning techniques for phishing detection.
\textit{eCrime Researchers Summit}.

\bibitem{b1}
Fette, I., Sadeh, N., \& Tomasic, A. (2007).
Learning to detect phishing emails.
\textit{Proceedings of the 16th International World Wide Web Conference (WWW)}.

\bibitem{b2}
Manning, C. D., Raghavan, P., \& Schütze, H. (2008).
\textit{Introduction to Information Retrieval}.
Cambridge University Press.

\bibitem{b2}
Mitchell, T. M. (1997).
\textit{Machine Learning}.
McGraw-Hill.

\bibitem{b3}
Han, J., Kamber, M., \& Pei, J. (2011).
\textit{Data Mining: Concepts and Techniques} (3rd ed.).
Morgan Kaufmann.

\bibitem{b4}
Jurafsky, D., \& Martin, J. H. (2009).
\textit{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}.
Prentice Hall.

\bibitem{b5}
Goodfellow, I., Bengio, Y., \& Courville, A. (2016).
\textit{Deep Learning}.
MIT Press.
\end{thebibliography}

\section*{Anexos}

\begin{itemize}
    \item \textbf{Anexo A:} Código (notebook Colab) con pipeline completo (preprocesamiento, vectorización, entrenamiento y evaluación).
    \item \textbf{Anexo B:} Parámetros exactos de los modelos y resultados de las 5 corridas cross-validation (media y desviación estándar).
    \item \textbf{Anexo C:} Plots (Figura 1, Figura 2, Figura 3) y matrices de confusión.
    \item \textbf{Anexo D:} Tabla detallada de distribución de trabajo y cronograma (según requisitos del curso).
\end{itemize}


\end{document}
