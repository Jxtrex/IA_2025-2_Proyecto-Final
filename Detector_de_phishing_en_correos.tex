\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{soul}
\usepackage{url}
\usepackage{hyperref}

% Cambios a nombres
\renewcommand{\abstractname}{Resumen}
\renewcommand{\IEEEkeywordsname}{Palabras clave}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Detector de phishing en correos electrónicos}

\author{\IEEEauthorblockN{1\textsuperscript{st} Sandro Carrillo}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
elcorreo@uni.pe}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Ariana Lopez}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
elcorreo@uni.pe}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Albert Argumedo}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
elcorreo@uni.pe}
\and
\IEEEauthorblockN{4\textsuperscript{th} Juan de Dios Lerzundi}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
juan.lerzundi.r@uni.pe}
}

\maketitle

\begin{abstract}
El phishing es una de las amenazas prevalentes en ciberseguridad. En este proyecto se implementó un sistema de detección automática basado en técnicas de aprendizaje supervisado y procesamiento de lenguaje natural.

El pipeline consta de preprocesamiento de texto, vectorización mediante TF-IDF y la evaluación de dos clasificacodres principales: Logistic Regressión (LR) y Random Forest. 

Además, se usó Multinomial Naive Bayes como modelo baseline.
\end{abstract}

\begin{IEEEkeywords}
phishing detection,email classification, TF-IDF, Logistic Regression, Random Forest, Naive Bayes, NLP, machine learning.
\end{IEEEkeywords}
%========================
\section{Introducción}

\subsection{Contexto y Motivación}
El correo electrónico, por su naturaleza masiva, es usado en ámbitos personales, académicos y empresariales; sin embargo, es un medio ideal para ataques maliciosos que buscan engañar a las personas para obtener información sensible. Este tipo de ataque se demonina \textit{phishing}, que se identifica mayormente por el uso de links maliciosos a sitios web que se encargan de obtener información como el número de tarjeta de crédito o credenciales de usuario \cite{b1}.  

\subsection{Importancia del Problema}
El correo electrónico, debido a su bajo coste de distribución, y a su adopción masiva, es uno de los principales vectores de ingeniería social. Esto \textbf{implica} que el riesgo de ser víctima de phishing va más allá del aspecto técnico y se centra en la capacidad del usuario para reaccionar ante estos ataques. En el pasado se emplearon filtros basados en listas negras, pero estos ya no resultan suficientes en el escenario actual, en el que los correos imitan con un mayor grado de exactitud el lenguaje natural como los dominios desde los cuales se envían.

En este contexto, el uso de técnicas de Inteligencia Artificial y de procesamiento de lenguaje natural ofrece una solución adaptable y escalable, que permite analizar el contenido y los metadatos del correo para identificar patrones complejos en el contenido del mensaje \cite{b2}. 

\subsection{Objetivos del Proyecto}

\subsubsection{Objetivo General}
\begin{itemize}
    \item Implementar un sistema de clasificación automática para identificar el phishing en correos electrónicos mediante técnicas de aprendizaje supervisado y una representación textual basada en TF-IDF.
\end{itemize}

\subsubsection{Objetivos Específicos}
\begin{itemize}
    \item Construir un pipeline reproducible que abarque la limpieza, normalización y vectorización del texto contenido en correos electrónicos etiquetados. (\textcolor{red}{\hl{QUITAR ESTO CUANDO SE HAYA DESCRITO TOTALMENTE EL PIPELINE}})[\hl{Pipeline reproducible}][Obj. aplicación]
    \item Implementar un modelo baseline utilizando Multinomial Naive Bayes para establecer un punto de referencia en términos de precisión, recall y F1-score. (\textcolor{red}{\hl{QUITAR ESTO CUANDO SE HALLA DEFINIDO LA IMPLEMENTACIÖN DEL BASELINE}})[\hl{Baseline con NB}][Obj. técnico]
    \item Entrenar y evaluar modelos avanzados, específicamente Logistic Regression y Random Forest. (\textcolor{red}{\hl{QUITAR ESTO CUANDO SE HAYA DADO UNA INTRODUCCIÓN AL ENTRENAMIENTO DEL MODELO}})[\hl{modelos LR y RF}][Obj. técnico]
    \item Compara el desempeño de los modelos considerando métricas relevantes para el problema de phishing, priorizando la red de falsos negativos medianteel análisis de recall. (\textcolor{red}{\hl{QUITAR ESTO CUANDO SE HAYA HECHO LA COMPARATIVA ENTRE LOS MODELOS}})[\hl{Comparación de modelos}][Obj. evaluación]
    \item Analizar las características lingüísticas más relevantes para la clasificación mediante coeficientes del modelo y la importancia de atributos. (\textcolor{red}{\hl{QUITAR ESTO CUANDO SE HAYA HECHO EL ANÁLISIS DE LA CLASIFICACIÓN DE LOS DATOS}})[\hl{Análisis de Features}][Obj. ético]
    \item Identificar oportunidades de mejora y establecer posibles líneas futuras de investigación, como el uso de embeddings contextualizados o modeos basados en Transformers. (\textcolor{red}{\hl{QUITAR ESTO CUANDO SE HAYA HECHO TRABAJO A FUTURO}})[\hl{Trabajo futuro}][Obj. ético]
\end{itemize}

\subsection{Restricciones}
\begin{itemize}
    \item El proyecto se centra en la detección de phishing general (no spear-phishing dirigido).
    \item El proyecto se limita a correos electrónicos ya etiquetados como phishing o legítimos; no se consideran metadatos como cabeceras completas o características asociadas a URLs externas. Usa el dataset en \cite{b3}.
    \item El archivo se encuentra preprocesao inicialmente.
    \item La partición de conjuntos de entrenamiento, validación y prueba se realizaa partir del archivo \texttt{phishing\_email.csv}, por lo que la representatividad depende de la distribución original del dataset.
    \item Se restringe el alcance a clasificadores supervisados clásicos como Naive Bayes, Logistic Regression y Random Forest.
    \item El entrenamiento se realiza en un entorno limitado como Google Colab, lo cual condiciona la elección de hiperparámetros y el tamaño de los modelos.
\end{itemize}

%========================
\section{Marco Teórico}

\subsection{Definición y naturaleza del phishing}
% T O D O
%=========
El phishing es una técnica de ingeniería social que emplea correos y otros canales simulando entidades legítimas para inducir a la víctima a revelar credenciales, ejecutar acciones o entregar información sensible. Sus variantes incluyen spear-phishing (ataques dirigidos), whaling (dirigido a ejecutivos) y ataques basados en URL/malware (\cite{b1} y \cite{b4}).


\subsection{Representación del texto y fundamentos de PLN}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Tokenización y normalización:} separación en tokens, conversión a minúsculas, normalización Unicode y tratamiento de caracteres especiales (URLs, correos, números).
    \item \textbf{Stopwords, lematización/stemming:} reducción de forma de palabras para disminuir sparsity.
    \item \textbf{Bag of Words (BoW) / n-grams:} representación básica que captura presencia/frecuencia de términos y frases cortas; útil con Naive Bayes y modelos lineales.
    \item \textbf{TF-IDF:} ponderación por frecuencia inversa a la frecuencia en corpus, reduce peso de términos comunes.
    \item \textbf{Embeddings y representaciones densas:} word2vec/GloVe representan palabras en espacios vectoriales densos; capturan similitud semántica y mejoran cuando se requiere generalización semántica (\cite{b5}; \cite{b6}).
    \item \textbf{Representaciones contextualizadas:} Transformers (BERT, RoBERTa) generan embeddings contextuales por token o frase y suelen mejorar el rendimiento en tareas de clasificación de texto si hay datos suficientes (\cite{b7}; \cite{b8}).
\end{itemize}

\subsection{Modelos de clasificación supervisada}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Naive Bayes (Multinomial/Bernoulli):} modelo probabilístico asumiendo independencia condicional de características; rápido y efectivo en text mining con bag-of-words/TF-IDF (Manning et al., 2008).
    \item \textbf{Árboles y ensamblados (Random Forest, Gradient Boosting):} capturan interacciones no lineales entre features; Random Forest es robusto a ruido y poca sintonía de hiperparámetros.
    \item \textbf{SVM:} buena separación en espacios de alta dimensión, efectivo con kernels y cuando hay margen claro entre clases.
    \item \textbf{Redes neuronales y Transformers:} CNNs/RNNs (antes dominantes en PLN) y hoy Transformers. Requieren más datos y cómputo, pero capturan mejor semántica y contexto.
    \item \textbf{Evaluación y selección de modelos:} emplear cross-validation, curvas ROC/PR, y reportar precision/recall/F1 por clase (especialmente recall para detectar phishing).
\end{itemize}

\subsection{Tipos de features relevantes en detección de phishing}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Contenido textual:} términos sospechosos (“password”, “verify”), patrones de lenguaje urgente, uso de imperativos, errores ortográficos.
    \item \textbf{Características estructurales:} presencia de URLs, número de enlaces, longitud del correo, HTML vs texto plano, uso de imágenes.
    \item \textbf{Características del remitente/metadatos:} dominio del remitente, coincidencia entre From y Return-Path, IP de origen, registros SPF/DKIM/DMARC.
    \item \textbf{Características de la URL:} longitud, uso de subdominios, caracteres especiales, presencia de IP en lugar de dominio, similitud visual con dominios legítimos (homoglyphs).
    \item \textbf{Comportamiento y contexto:} tasa de envíos por remitente, patrones temporales, reputación del dominio.
\end{itemize}

\subsection{Problemas técnicos centrales}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Desbalance de clases:} los correos legítimos suelen superar en número a los phishing; requiere técnicas de muestreo (oversampling/SMOTE), o métricas robustas (PR-AUC).
    \item \textbf{Drift y evolución de ataques:} campañas nuevas cambian vocabulario y tácticas; necesario reentrenamiento y monitorización.
    \item \textbf{Adversarialidad:} atacantes pueden adaptar textos para evadir detectores; conviene estudiar adversarial ML y robustez (Biggio \& Roli, 2018).
\end{itemize}
%========================
\section{Estado del Arte}
% T O D O
%=========

\subsection{Enfoques históricos y baselines}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Reglas heurísticas y blacklists:} sistemas tempranos usaban listas negras de dominios/URLs y reglas de coincidencia de patrones; funcionan contra técnicas conocidas pero no contra evasiones (nazario corp).
    \item \textbf{Filtrado bayesiano y ML clásico:} Multinomial Naive Bayes y SVMs se convirtieron en baseline por su eficiencia y desempeño en datasets textuales (Abu-Nimeh et al., 2007; Fette et al., 2007).
\end{itemize}

\subsection{Métodos basados en características (features)}
% T O D O
%=========

\begin{itemize}
    \item Investigaciones tempranas mostraron que combinar features de contenido, URL y metadatos mejora la detección. Garera et al. (2007) y Bergholz et al. (2010) analizaron heurísticas de URL y contenido.
    \item Modelos de ensamblado (Random Forest, Gradient Boosting) demostraron robustez frente a ruido y capacidad para priorizar features relevantes (importancia de variables).
\end{itemize}

\subsection{Deep learning y representaciones modernas}
% T O D O
%=========

\begin{itemize}
    \item \textbf{CNN/RNN:} capturan patrones locales y secuencias (uso en clasificación de correo).
    \item \textbf{Transformers (BERT y variantes):} han mostrado mejoras marcadas en clasificación de texto y tareas de seguridad cuando se dispone de datos de calidad o se hace fine-tuning (Devlin et al., 2019).
    \item \textbf{Enfoques híbridos:} combinar embeddings BERT con features manuales (URL, encabezados) suele ser altamente efectivo, aprovecha semántica de texto y reglas estructurales.
    \item \textbf{}
\end{itemize}

\subsection{Datasets y benchmarks comunes}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Enron Email Dataset:} corpus grande de correos empresariales (usado para spam/filtrado y como fuente de ham).
    \item \textbf{SpamAssassin public corpus:} colección etiquetada de spam y ham.
    \item \textbf{Phishing corpora / repositorios:} conjuntos públicos con muestras de phishing (por ejemplo PhishTank/Nazario/PhishCorpus).
    \item Investigaciones recientes también construyen datasets a partir de correos reales anotados y de campañas de phishing actuales; calibrar modelos en datos recientes es crucial.
\end{itemize}

\subsection{Evaluación práctica y métricas}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Recall prioritario:} en detección de phishing, disminuir falsos negativos suele ser más importante que minimizar falsos positivos.
    \item \textbf{PR-AUC vs ROC-AUC:} cuando la clase positiva es rara, PR-AUC refleja mejor la capacidad del clasificador para identificar positivos relevantes.
    \item \textbf{Explicabilidad y análisis de errores:} LIME/SHAP son herramientas para entender decisiones y depurar falsos positivos/negativos.
\end{itemize}

\subsection{Resumen de hallazgos empíricos}
% T O D O
%=========

\begin{itemize}
    \item Los modelos que combinan features manuales (URL, encabezados) con representaciones semánticas (embeddings o Transformers) tienden a obtener los mejores resultados.
    \item Random Forest y Gradient Boosting son fuertes competidores cuando los recursos son limitados; Transformers dominan cuando hay datos y cómputo suficientes.
    \item La robustez a nuevas campañas requiere pipelines de re-entrenamiento y detección de deriva.
\end{itemize}

%========================
\section{Metodología}
% T O D O
%=========
El sistema consta de los siguientes módulos:

\subsection{Flujo General}
% T O D O
%=========
\begin{enumerate}
    \item \textbf{Preprocesamiento:} normalización y limpieza del texto del correo (remoción de HTML, URLs, tokens no alfabéticos), reemplazo de direcciones y números por tokens especiales, minúsculas, eliminación de stopwords, lematización/stemming.
    \item \textbf{Extracción de características:} representación mediante TF-IDF (n-grams unigrama y bigrama), inclusión opcional de features booleanos (presencia de URL, cantidad de enlaces, uso de palabras claves sospechosas) y metadatos (dominio remitente, encabezados).
    \item \textbf{Partición de datos y balanceo:} división Train/Test (p. ej. 80/20) y validación cruzada (5-fold). En presencia de desbalance, aplicación de técnicas como SMOTE o submuestreo estratificado.
    \item \textbf{Entrenamiento:} entrenamiento de Multinomial Naive Bayes y RandomForestClassifier (scikit-learn).
    \item \textbf{Evaluación:} cálculo de accuracy, precision, recall, F1, ROC-AUC y PR-AUC; generación de matriz de confusión y análisis de importancia de variables (Random Forest).
    \item \textbf{Análisis y despliegue:} análisis de casos erróneos, propuestas de mejora y diseño de prototipo para integración en pipeline de correo.
\end{enumerate}

\subsection{Descripción del Dataset}
% T O D O
%=========
Para el desarrollo y evaluación de los modelos propuestos, se utilizó el "Phishing Email Dataset" obtenido del repositorio de Kaggle (Alam, 2020). Este conjunto de datos es una compilación robusta que integra múltiples fuentes de referencia en el ámbito de la ciberseguridad, incluyendo el corpus de Enron para correos corporativos legítimos, el dataset de SpamAssassin y colecciones de correos fraudulentos como el "Nigerian Fraud" y "Nazario".

El dataset final consolidado consta de un total de 82,486 registros únicos. Una ventaja significativa de este recurso es su balance de clases, reduciendo el sesgo natural que suele existir en la detección de anomalías: contiene 42,891 correos etiquetados como phishing (aproximadamente el 52\%) y 39,595 correos legítimos (48\%). Los datos se presentan en dos columnas principales: \texttt{text\_combined}, que contiene la concatenación del asunto y el cuerpo del mensaje sin metadatos de cabecera complejos, y la etiqueta binaria \texttt{label} (0 para legítimo, 1 para phishing).

\subsection{Preprocesamiento}
% T O D O
%=========

\begin{enumerate}
    \item \textbf{Limpieza:} eliminar etiquetas HTML, normalizar saltos de línea, eliminar caracteres no ASCII si procede.
    \item \textbf{Normalización:} pasar a minúsculas, normalizar acentos.
    \item \textbf{Tokens especiales:} reemplazar URLs por \texttt{<URL>}, direcciones de email por \texttt{<EMAIL>} y números por \texttt{<NUM>}.
    \item \textbf{Tokenización:} separación en tokens — se consideraron n-grams (1,2).
    \item \textbf{Stopwords \& Lematización:} remover palabras funcionales y lematizar para reducir variabilidad morfológica.
    \item \textbf{Vectorización:} TF-IDF con límite de vocabulario (p. ej. max\_features=20,000), ngram\_range=(1,2), y sublinear\_tf=True.
\end{enumerate}

\subsection{Modelos}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Multinomial Naive Bayes:} \hl{sklearn.naive\_bayes.MultinomialNB(alpha=1.0)} como baseline para datos textuales.
    \item \textbf{Random Forest:} \hl{sklearn.ensemble.RandomForestClassifier} \hl{(n\_estimators=200, max\_depth=None, n\_jobs=-1, random\_state=42)} usado para capturar interacciones entre tokens y es robusto a features ruidosos.
    \item \textbf{Validación:} 5-fold cross-validation y evaluación sobre test holdout (80/20). Se reportan métricas promedio y desviación estándar.
\end{itemize}

\subsection{Métricas de evaluación}
% T O D O
%=========

\begin{itemize}
    \item \textbf{Precision, Recall, F1-score:} para la clase positiva (phishing).
    \item \textbf{ROC-AUC y PR-AUC:} dado que la clase positiva puede ser minoritaria, PR-AUC es útil para valorar el rendimiento en detección.
    \item \textbf{Matriz de confusión:} análisis de falsos positivos y falsos negativos (importante por coste distinto de ambos errores).
\end{itemize}

%========================
\section{Resultados}
% T O D O
%=========

\subsection{Tabla comparativa de métricas}
% T O D O
%=========

\blindtext

\subsection{Matrices de confusión}
% T O D O
%=========

\blindtext

\subsection{Figuras}
% T O D O
%=========
%========================
\section{Discusión}
% T O D O
%=========

% \subsection{Comparación de Modelos}

% \begin{itemize}
%     \item \blindtext
% \end{itemize}

% \subsection{Preprocesamiento}

% \blindtext

% \subsection{Limitaciones}

% \blindtext

\subsection{Consideraciones Éticas}
% T O D O
%=========

\begin{itemize}
    \item El análisis de correos electrónicos implica acceso a información potencialmente sensible (mensajes privados, datos personales). Es obligatorio aplicar principios de minimización de datos, anonimización/pseudonimización y políticas de retención.
    \item La sobre-representación de ciertos idiomas puede traducirse en mayor tasa de falsos positivos para grupos específicos, siendo idiomas minoritarios, esto añade un sesgo en los datos de entrenamiento.
    \item Para tratar el sesgo en los datos se recomendaría evaluar métricas por subgrupos, usar muestreo estratificado y técnicas de debiasing.
    \item La aparición de falsos positivos puede bloquear comunicaciones legítimas y afectar operaciones como pérdida de informacióno demora. Ante esto se deberían aplicar políticas de cuarentena, notificaciones o vías de apelación, umbrales ajustables según el criterio del usuario u organización.
\end{itemize}

%========================
\section{Conclusiones}
% T O D O
%=========

\subsection{Conclusiones Principales}
% T O D O
%=========

\blindtext

\subsection{Trabajo a Futuro}
% T O D O
%=========

\blindtext
%========================
\begin{thebibliography}{00}

\bibitem{b1}
I.~Fette, N.~Sadeh, and A.~Tomasic,
``Learning to detect phishing emails,''
in \textit{Proceedings of the 16th International Conference on World Wide Web (WWW '07)},
Association for Computing Machinery, New York, NY, USA, 2007, pp.~649--656.
doi: \href{https://doi.org/10.1145/1242572.1242660}{10.1145/1242572.1242660}.

    \bibitem{b2}
S.~Abu-Nimeh, D.~Nappa, X.~Wang, and S.~Nair,
``A comparison of machine learning techniques for phishing detection,''
in \textit{Proceedings of the Anti-Phishing Working Groups 2nd Annual eCrime Researchers Summit (eCrime '07)},
Association for Computing Machinery, New York, NY, USA, 2007, pp.~60--69.
doi: \href{https://doi.org/10.1145/1299015.1299021}{10.1145/1299015.1299021}.

\bibitem{b3}
Naser Abdullah Alam. (2024). Phishing Email Dataset [Data set]. Kaggle. \url{https://doi.org/10.34740/KAGGLE/DS/5074342}


\bibitem{b4}
Garera, S., Provos, N., Chew, M., \& Rubin, A. D. (2007).
A framework for detection and measurement of phishing attacks.
En \textit{Proceedings of the 2007 ACM Workshop on Recurring Malcode (WORM '07)}
(pp. 1--8). Association for Computing Machinery.
\url{https://doi.org/10.1145/1314389.1314391}

\bibitem{b5}
Mikolov, T., Chen, K., Corrado, G., \& Dean, J. (2013).
\textit{Efficient estimation of word representations in vector space}.
arXiv preprint arXiv:1301.3781.
\url{https://arxiv.org/abs/1301.3781}

\bibitem{b6}
Pennington, J., Socher, R., \& Manning, C. D. (2014).
GloVe: Global vectors for word representation.
En Moschitti, A., Pang, B., \& Daelemans, W. (Eds.),
\textit{Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)}
(pp. 1532--1543). Association for Computational Linguistics.
\url{https://aclanthology.org/D14-1162/}

\bibitem{b7}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \& Polosukhin, I. (2023).
\textit{Attention is all you need}.
arXiv preprint arXiv:1706.03762.
\url{https://arxiv.org/abs/1706.03762}

\bibitem{b8}
Devlin, J., Chang, M.-W., Lee, K., \& Toutanova, K. (2019).
\textit{BERT: Pre-training of deep bidirectional transformers for language understanding}.
arXiv preprint arXiv:1810.04805.
\url{https://arxiv.org/abs/1810.04805}

%============================

\bibitem{b4}
Manning, C. D., Raghavan, P., \& Schütze, H. (2009). Introduction to Information Retrieval (Online edition). Cambridge University Press. Disponible en \href{https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf}{PDF}

\bibitem{b5}
Mitchell, T. M. (1997). \textit{Machine learning}. McGraw-Hill Science/Engineering/Math.

\bibitem{b6}
Han, J., Kamber, M., \& Pei, J. (2011).
\textit{Data mining: Concepts and techniques} (3rd ed.).
Recuperado de \url{https://www.scholartext.com/book/88809627?_locale=fr}

\bibitem{b7}
Jurafsky, D., \& Martin, J. H. (2009).
\textit{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}.
Prentice Hall.

\bibitem{b8}
Goodfellow, I., Bengio, Y., \& Courville, A. (2016).
\textit{Deep learning}. MIT Press.
Recuperado de \url{http://www.deeplearningbook.org}

\bibitem{b9}
Bergholz, A., De Beer, J., Glahn, S., Moens, M.-F., Paa\ss{}, G., \& Strobel, S. (2010).
New filtering approaches for phishing email.
\textit{Journal of Computer Security, 18}(1), 7--35.

\bibitem{b10}
Biggio, B., \& Roli, F. (2018).
Wild patterns: Ten years after the rise of adversarial machine learning.
\textit{Pattern Recognition, 84}, 317--331.
\url{https://doi.org/10.1016/j.patcog.2018.07.023}





\bibitem{b13}
Goodfellow, I. J., Shlens, J., \& Szegedy, C. (2015).
\textit{Explaining and harnessing adversarial examples}.
arXiv preprint arXiv:1412.6572.
\url{https://arxiv.org/abs/1412.6572}

\bibitem{b14}
Lundberg, S., \& Lee, S.-I. (2017).
\textit{A unified approach to interpreting model predictions}.
arXiv preprint arXiv:1705.07874.
\url{https://arxiv.org/abs/1705.07874}




\bibitem{b17}
Ribeiro, M. T., Singh, S., \& Guestrin, C. (2016).
\textit{"Why should I trust you?": Explaining the predictions of any classifier}.
arXiv preprint arXiv:1602.04938.
\url{https://arxiv.org/abs/1602.04938}



\bibitem{b19}
European Parliament and Council. (2016).
Regulation (EU) 2016/679 (General Data Protection Regulation).
\textit{Official Journal of the European Union}.

\bibitem{b20}
Elhoseny, M., Abdel-Salam, M., Khafaga, D. S., Aldakheel, E. A., \& El-Hasnony, I. M. (2025). Robust Optimized Deep Learning-Based Phishing Detection Framework for semantic web systems using boosted triangular topology aggregation optimization. International Journal on Semantic Web and Information Systems, 21(1), 1-58. \url{https://doi.org/10.4018/ijswis.388181}

\bibitem{b21}
Naser Abdullah Alam. (2024). Phishing Email Dataset [Data set]. Kaggle. \url{https://doi.org/10.34740/KAGGLE/DS/5074342}

\end{thebibliography}

\section*{Anexos}

\begin{itemize}
    \item \textbf{Anexo A:} Código (notebook Colab) con pipeline completo (preprocesamiento, vectorización, entrenamiento y evaluación).
    \item \textbf{Anexo B:} Parámetros exactos de los modelos y resultados de las 5 corridas cross-validation (media y desviación estándar).
    \item \textbf{Anexo C:} Plots (Figura 1, Figura 2, Figura 3) y matrices de confusión.
    \item \textbf{Anexo D:} Tabla detallada de distribución de trabajo y cronograma (según requisitos del curso).
\end{itemize}


\end{document}
