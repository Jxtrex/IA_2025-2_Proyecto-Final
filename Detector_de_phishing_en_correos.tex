\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{soul}

% Cambios a nombres
\renewcommand{\abstractname}{Resumen}
\renewcommand{\IEEEkeywordsname}{Palabras clave}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Detector de phishing en correos electrónicos}

\author{\IEEEauthorblockN{1\textsuperscript{st} Sandro Carrillo}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
elcorreo@uni.pe}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Ariana Lopez}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
elcorreo@uni.pe}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Albert Argumedo}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
elcorreo@uni.pe}
\and
\IEEEauthorblockN{4\textsuperscript{th} Juan de Dios Lerzundi}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
juan.lerzundi.r@uni.pe}
}

\maketitle

\begin{abstract}
El phishing por correo electrónico es una de las amenazas más frecuentes en ciberseguridad. Este trabajo presenta un sistema de detección de correos de phishing basado en técnicas de aprendizaje supervisado y procesamiento de lenguaje natural. Se desarrolló un pipeline que incluye limpieza de texto, tokenización y vectorización con TF-IDF, y se evaluaron dos clasificadores: Multinomial Naive Bayes y Random Forest. Los resultados (placeholders) muestran que Random Forest obtiene mayor recall y F1-score, indicando una mejor capacidad para identificar correos maliciosos. Finalmente, se discuten las implicancias del preprocesamiento, limitaciones del modelo y líneas de mejora como el uso de embeddings contextualizados.
\end{abstract}

\begin{IEEEkeywords}
phishing, clasificación, TF-IDF, Random Forest, Naive Bayes, aprendizaje supervisado.
\end{IEEEkeywords}
%========================
\section{Introducción}

\subsection{Contexto y Motivación}
El correo electrónico es una herramienta de comunicación masiva usada en ámbitos personales, académicos y empresariales. Su popularidad la convierte en un vector atractivo para ataques de ingeniería social y fraude digital. El phishing (y su forma dirigida spear-phishing) busca engañar al usuario para obtener credenciales o información sensible, provocando pérdidas económicas, robo de identidad y compromiso de sistemas (Fette, Sadeh, \& Tomasic, 2007).

\subsection{Importancia del Problema}
Los filtros tradicionales basados en listas negras o reglas simples no son suficientemente robustos frente a mensajes que imitan lenguaje legítimo o utilizan pequeñas variaciones en dominios. Por ello, la aplicación de técnicas de IA y procesamiento de lenguaje natural (PLN) para analizar contenido y metadatos del correo es una línea prometedora para mejorar la detección (Abu-Nimeh et al., 2007).

\subsection{Objetivos del Proyecto}
Desarrollar y evaluar un prototipo de detector de phishing en correos electrónicos utilizando técnicas de Machine Learning y PLN, comparando Naive Bayes y Random Forest sobre un dataset preprocesado, con el objetivo de maximizar la detección (recall) y mantener una F1 alta.


\subsection{Restricciones}
\begin{itemize}
    \item El proyecto se centra en la detección de phishing general (no spear-phishing dirigido).
    \item Se parte de un dataset ya preprocesado (el informe detalla el proceso de preprocesamiento realizado).
\end{itemize}

%========================
\section{Marco Teórico}

\subsection{Definición y naturaleza del phishing}
El phishing es una técnica de ingeniería social que emplea correos (u otros canales) simulando entidades legítimas para inducir a la víctima a revelar credenciales, ejecutar acciones o entregar información sensible. Sus variantes incluyen spear-phishing (ataques dirigidos), whaling (dirigido a ejecutivos) y ataques basados en URL/malware (ver Garera et al., 2007; Fette et al., 2007).


\subsection{Representación del texto y fundamentos de PLN}

\begin{itemize}
    \item \textbf{Tokenización y normalización:} separación en tokens, conversión a minúsculas, normalización Unicode y tratamiento de caracteres especiales (URLs, correos, números).
    \item \textbf{Stopwords, lematización/stemming:} reducción de forma de palabras para disminuir sparsity.
    \item \textbf{Bag-of-Words / n-grams:} representación básica que captura presencia/frecuencia de términos y frases cortas; útil con Naive Bayes y modelos lineales.
    \item \textbf{TF-IDF:} ponderación por frecuencia inversa a la frecuencia en corpus, reduce peso de términos comunes.
    \item \textbf{Embeddings y representaciones densas:} word2vec/GloVe representan palabras en espacios vectoriales densos; capturan similitud semántica y mejoran cuando se requiere generalización semántica (Mikolov et al., 2013; Pennington et al., 2014).
    \item \textbf{Representaciones contextualizadas:} Transformers (BERT, RoBERTa) generan embeddings contextuales por token/frase y suelen mejorar el rendimiento en tareas de clasificación de texto si hay datos suficientes (Vaswani et al., 2017; Devlin et al., 2019).
\end{itemize}

\subsection{Modelos de clasificación supervisada}

\begin{itemize}
    \item \textbf{Naive Bayes (Multinomial/Bernoulli):} modelo probabilístico asumiendo independencia condicional de características; rápido y efectivo en text mining con bag-of-words/TF-IDF (Manning et al., 2008).
    \item \textbf{Árboles y ensamblados (Random Forest, Gradient Boosting):} capturan interacciones no lineales entre features; Random Forest es robusto a ruido y poca sintonía de hiperparámetros.
    \item \textbf{SVM:} buena separación en espacios de alta dimensión, efectivo con kernels y cuando hay margen claro entre clases.
    \item \textbf{Redes neuronales y Transformers:} CNNs/RNNs (antes dominantes en PLN) y hoy Transformers. Requieren más datos y cómputo, pero capturan mejor semántica y contexto.
    \item \textbf{Evaluación y selección de modelos:} emplear cross-validation, curvas ROC/PR, y reportar precision/recall/F1 por clase (especialmente recall para detectar phishing).
\end{itemize}

\subsection{Tipos de features relevantes en detección de phishing}

\begin{itemize}
    \item \textbf{Contenido textual:} términos sospechosos (“password”, “verify”), patrones de lenguaje urgente, uso de imperativos, errores ortográficos.
    \item \textbf{Características estructurales:} presencia de URLs, número de enlaces, longitud del correo, HTML vs texto plano, uso de imágenes.
    \item \textbf{Características del remitente/metadatos:} dominio del remitente, coincidencia entre From y Return-Path, IP de origen, registros SPF/DKIM/DMARC.
    \item \textbf{Características de la URL:} longitud, uso de subdominios, caracteres especiales, presencia de IP en lugar de dominio, similitud visual con dominios legítimos (homoglyphs).
    \item \textbf{Comportamiento y contexto:} tasa de envíos por remitente, patrones temporales, reputación del dominio.
\end{itemize}

\subsection{Problemas técnicos centrales}

\begin{itemize}
    \item \textbf{Desbalance de clases:} los correos legítimos suelen superar en número a los phishing; requiere técnicas de muestreo (oversampling/SMOTE), o métricas robustas (PR-AUC).
    \item \textbf{Drift y evolución de ataques:} campañas nuevas cambian vocabulario y tácticas; necesario reentrenamiento y monitorización.
    \item \textbf{Adversarialidad:} atacantes pueden adaptar textos para evadir detectores; conviene estudiar adversarial ML y robustez (Biggio \& Roli, 2018).
\end{itemize}
%========================
\section{Estado del Arte}

%========================
\section{Metodología}

El sistema consta de los siguientes módulos:

\subsection{Flujo General}
\begin{enumerate}
    \item \textbf{Preprocesamiento:} normalización y limpieza del texto del correo (remoción de HTML, URLs, tokens no alfabéticos), reemplazo de direcciones y números por tokens especiales, minúsculas, eliminación de stopwords, lematización/stemming.
    \item \textbf{Extracción de características:} representación mediante TF-IDF (n-grams unigrama y bigrama), inclusión opcional de features booleanos (presencia de URL, cantidad de enlaces, uso de palabras claves sospechosas) y metadatos (dominio remitente, encabezados).
    \item \textbf{Partición de datos y balanceo:} división Train/Test (p. ej. 80/20) y validación cruzada (5-fold). En presencia de desbalance, aplicación de técnicas como SMOTE o submuestreo estratificado.
    \item \textbf{Entrenamiento:} entrenamiento de Multinomial Naive Bayes y RandomForestClassifier (scikit-learn).
    \item \textbf{Evaluación:} cálculo de accuracy, precision, recall, F1, ROC-AUC y PR-AUC; generación de matriz de confusión y análisis de importancia de variables (Random Forest).
    \item \textbf{Análisis y despliegue:} análisis de casos erróneos, propuestas de mejora y diseño de prototipo para integración en pipeline de correo.
    \item \textbf{}
    \item \textbf{}
\end{enumerate}

\subsection{Preprocesamiento}

\begin{enumerate}
    \item \textbf{Limpieza:} eliminar etiquetas HTML, normalizar saltos de línea, eliminar caracteres no ASCII si procede.
    \item \textbf{Normalización:} pasar a minúsculas, normalizar acentos.
    \item \textbf{Tokens especiales:} reemplazar URLs por \texttt{<URL>}, direcciones de email por \texttt{<EMAIL>} y números por \texttt{<NUM>}.
    \item \textbf{Tokenización:} separación en tokens — se consideraron n-grams (1,2).
    \item \textbf{Stopwords \& Lematización:} remover palabras funcionales y lematizar para reducir variabilidad morfológica.
    \item \textbf{Vectorización:} TF-IDF con límite de vocabulario (p. ej. max\_features=20,000), ngram\_range=(1,2), y sublinear\_tf=True.
\end{enumerate}

\subsection{Modelos}

\begin{itemize}
    \item \textbf{Multinomial Naive Bayes:} \hl{sklearn.naive\_bayes.MultinomialNB(alpha=1.0)} como baseline para datos textuales.
    \item \textbf{Random Forest:} \hl{sklearn.ensemble.RandomForestClassifier} \hl{(n\_estimators=200, max\_depth=None, n\_jobs=-1, random\_state=42)} usado para capturar interacciones entre tokens y es robusto a features ruidosos.
    \item \textbf{Validación:} 5-fold cross-validation y evaluación sobre test holdout (80/20). Se reportan métricas promedio y desviación estándar.
\end{itemize}

\subsection{Métricas de evaluación}

\begin{itemize}
    \item \textbf{Precision, Recall, F1-score:} para la clase positiva (phishing).
    \item \textbf{ROC-AUC y PR-AUC:} dado que la clase positiva puede ser minoritaria, PR-AUC es útil para valorar el rendimiento en detección.
    \item \textbf{Matriz de confusión:} análisis de falsos positivos y falsos negativos (importante por coste distinto de ambos errores).
\end{itemize}

%========================
\section{Resultados}

\subsection{Tabla comparativa de métricas}

\blindtext

\subsection{Matrices de confusión}

\blindtext

\subsection{Figuras}
%========================
\section{Discusión}

\subsection{Comparación de Modelos}

\begin{itemize}
    \item \blindtext
\end{itemize}

\subsection{Preprocesamiento}

\blindtext

\subsection{Limitaciones}

\blindtext

\subsection{Consideraciones Éticas}

\blindtext
%========================
\section{Conclusiones}

\subsection{Conclusiones Principales}

\blindtext

\subsection{Trabajo a Futuro}

\blindtext
%========================
\begin{thebibliography}{00}
\bibitem{AbuNimeh2007}
Abu-Nimeh, S., Nappa, D., Wang, X., \& Nair, S. (2007).
A comparison of machine learning techniques for phishing detection.
\textit{eCrime Researchers Summit}.

\bibitem{b1}
Fette, I., Sadeh, N., \& Tomasic, A. (2007).
Learning to detect phishing emails.
\textit{Proceedings of the 16th International World Wide Web Conference (WWW)}.

\bibitem{b3}
Manning, C. D., Raghavan, P., \& Schütze, H. (2008).
\textit{Introduction to Information Retrieval}.
Cambridge University Press.

\bibitem{b4}
Mitchell, T. M. (1997).
\textit{Machine Learning}.
McGraw-Hill.

\bibitem{b5}
Han, J., Kamber, M., \& Pei, J. (2011).
\textit{Data Mining: Concepts and Techniques} (3rd ed.).
Morgan Kaufmann.

\bibitem{b6}
Jurafsky, D., \& Martin, J. H. (2009).
\textit{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}.
Prentice Hall.

\bibitem{b7}
Goodfellow, I., Bengio, Y., \& Courville, A. (2016).
\textit{Deep Learning}.
MIT Press.
\end{thebibliography}

\section*{Anexos}

\begin{itemize}
    \item \textbf{Anexo A:} Código (notebook Colab) con pipeline completo (preprocesamiento, vectorización, entrenamiento y evaluación).
    \item \textbf{Anexo B:} Parámetros exactos de los modelos y resultados de las 5 corridas cross-validation (media y desviación estándar).
    \item \textbf{Anexo C:} Plots (Figura 1, Figura 2, Figura 3) y matrices de confusión.
    \item \textbf{Anexo D:} Tabla detallada de distribución de trabajo y cronograma (según requisitos del curso).
\end{itemize}


\end{document}
