\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{soul}
\usepackage{url}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[cache=false]{minted}
\usepackage{fontspec}
\usepackage{float}

% Nueva fuenta para los listings
\newfontfamily\codefont[Path=./fonts/]{JetBrainsMono-Regular.ttf}
\renewcommand{\ttfamily}{\codefont}  % Map to default typewriter family used by minted



% Definir comandos
\renewcommand{\abstractname}{Resumen}
\renewcommand{\IEEEkeywordsname}{Palabras clave}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Detector de phishing en correos electrónicos}

\author{\IEEEauthorblockN{1\textsuperscript{st} Sandro Carrillo}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
sandro.carrillo.j@uni.pe}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Ariana Lopez}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
ariana.lopez.j@uni.pe}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Albert Argumedo}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
albert.argumedo.r@uni.pe}
\and
\IEEEauthorblockN{4\textsuperscript{th} Juan de Dios Lerzundi}
\IEEEauthorblockA{\textit{Escuela de Ciencia de la Computación} \\
\textit{Universidad Nacional de Ingeniería}\\
Lima, Perú \\
juan.lerzundi.r@uni.pe}
}

\maketitle

\begin{abstract}
El phishing es una de las amenazas prevalentes en ciberseguridad. En este proyecto se implementó un sistema de detección automática basado en técnicas de aprendizaje supervisado y procesamiento de lenguaje natural.

El pipeline consta de preprocesamiento de texto, vectorización mediante TF-IDF y la evaluación de dos clasificacodres principales: Logistic Regressión (LR) y Random Forest. 

Además, se usó Multinomial Naive Bayes como modelo baseline.
\end{abstract}

\begin{IEEEkeywords}
phishing detection,email classification, TF-IDF, Logistic Regression, Random Forest, Naive Bayes, NLP, machine learning.
\end{IEEEkeywords}
%========================
\section{Introducción}

\subsection{Contexto y Motivación}
El correo electrónico, por su naturaleza masiva, es usado en ámbitos personales, académicos y empresariales; sin embargo, es un medio ideal para ataques maliciosos que buscan engañar a las personas para obtener información sensible. Este tipo de ataque se demonina \textit{phishing}, que se identifica mayormente por el uso de links maliciosos a sitios web que se encargan de obtener información como el número de tarjeta de crédito o credenciales de usuario \cite{b1}.  

\subsection{Importancia del Problema}
El correo electrónico, debido a su bajo coste de distribución, y a su adopción masiva, es uno de los principales vectores de ingeniería social. Esto implica que el riesgo de ser víctima de phishing va más allá del aspecto técnico y se centra en la capacidad del usuario para reaccionar ante estos ataques. En el pasado se emplearon filtros basados en listas negras, pero estos ya no resultan suficientes en el escenario actual, en el que los correos imitan con un mayor grado de exactitud el lenguaje natural como los dominios desde los cuales se envían.

En este contexto, el uso de técnicas de Inteligencia Artificial y de procesamiento de lenguaje natural ofrece una solución adaptable y escalable, que permite analizar el contenido y los metadatos del correo para identificar patrones complejos en el contenido del mensaje \cite{b2}. 

\subsection{Objetivos del Proyecto}

\subsubsection{Objetivo General}
\begin{itemize}
    \item Implementar un sistema de clasificación automática para identificar el phishing en correos electrónicos mediante técnicas de aprendizaje supervisado y una representación textual basada en TF-IDF.
\end{itemize}

\subsubsection{Objetivos Específicos}
\begin{itemize}
    \item Construir un pipeline reproducible que abarque la limpieza, normalización y vectorización del texto contenido en correos electrónicos etiquetados. [Obj. aplicación]
    \item Implementar un modelo baseline utilizando Multinomial Naive Bayes para establecer un punto de referencia en términos de precisión, recall y F1-score. [Obj. técnico]
    \item Entrenar y evaluar modelos avanzados, específicamente Logistic Regression y Random Forest. [Obj. técnico]
    \item Compara el desempeño de los modelos considerando métricas relevantes para el problema de phishing, priorizando la red de falsos negativos medianteel análisis de recall. [Obj. evaluación]
    \item Analizar las características lingüísticas más relevantes para la clasificación mediante coeficientes del modelo y la importancia de atributos. [Obj. ético]
    \item Identificar oportunidades de mejora y establecer posibles líneas futuras de investigación, como el uso de embeddings contextualizados o modeos basados en Transformers. [Obj. ético]
\end{itemize}

\subsection{Restricciones}
\begin{itemize}
    \item El proyecto se centra en la detección de phishing general (no spear-phishing dirigido).
    \item El proyecto se limita a correos electrónicos ya etiquetados como phishing o legítimos; no se consideran metadatos como cabeceras completas o características asociadas a URLs externas. Usa el dataset en \cite{b3}.
    \item El archivo se encuentra preprocesao inicialmente.
    \item La partición de conjuntos de entrenamiento, validación y prueba se realizaa partir del archivo \texttt{phishing\_email.csv}, por lo que la representatividad depende de la distribución original del dataset.
    \item Se restringe el alcance a clasificadores supervisados clásicos como Naive Bayes, Logistic Regression y Random Forest.
    \item El entrenamiento se realiza en un entorno limitado como Google Colab, lo cual condiciona la elección de hiperparámetros y el tamaño de los modelos.
\end{itemize}

%========================
\section{Marco Teórico}

\subsection{Definición y naturaleza del phishing}
El phishing es una técnica de ingeniería social que emplea correos y otros canales simulando entidades legítimas para inducir a la víctima a revelar credenciales, ejecutar acciones o entregar información sensible. Sus variantes incluyen spear-phishing (ataques dirigidos), whaling (dirigido a ejecutivos) y ataques basados en URL o malware (\cite{b1} y \cite{b4}).


\subsection{Representación del texto y fundamentos de PLN}

\begin{itemize}
    \item \textbf{Tokenización y normalización:} separación en tokens, conversión a minúsculas, normalización Unicode y tratamiento de caracteres especiales (URLs, correos, números).
    \item \textbf{Stopwords, lematización, stemming:} reducción de forma de palabras para disminuir sparsity.
    \item \textbf{Bag of Words (BoW) , n-grams:} representación básica que captura presencia/frecuencia de términos y frases cortas; útil con Naive Bayes y modelos lineales.
    \item \textbf{TF-IDF:} ponderación por frecuencia inversa a la frecuencia en corpus, reduce peso de términos comunes.
    \item \textbf{Embeddings y representaciones densas:} word2vec y GloVe representan palabras en espacios vectoriales densos; capturan similitud semántica y mejoran cuando se requiere generalización semántica (\cite{b5}, \cite{b6}).
    \item \textbf{Representaciones contextualizadas:} Transformers (BERT, RoBERTa) generan embeddings contextuales por token o frase y suelen mejorar el rendimiento en tareas de clasificación de texto si hay datos suficientes (\cite{b7}, \cite{b8}).
\end{itemize}

\subsection{Modelos de clasificación supervisada}

\begin{itemize}
    \item \textbf{Naive Bayes (Multinomial, Bernoulli):} modelo probabilístico asumiendo independencia condicional de características; rápido y efectivo en text mining con Bag of Words y TF-IDF (\cite{b9}).
    \item \textbf{Árboles y ensamblados (Random Forest):} capturan interacciones no lineales entre features; Random Forest es robusto a ruido y poca sintonía de hiperparámetros.
    \item \textbf{SVM:} buena separación en espacios de alta dimensión, efectivo con kernels y cuando hay margen claro entre clases.
    \item \textbf{Redes neuronales y Transformers:} CNNs, RNNs (antes dominantes en PLN) y hoy Transformers. Requieren más datos y cómputo, pero capturan mejor semántica y contexto.
    \item \textbf{Evaluación y selección de modelos:} emplear cross validation, curvas ROC-PR, y reportar precision,recall y F1 por clase (especialmente recall para detectar phishing).
\end{itemize}

\subsection{Tipos de features relevantes en detección de phishing}

\begin{itemize}
    \item \textbf{Contenido textual:} términos sospechosos como \textit{\textbf{“password”}}, \textbf{\textit{“verify”}}, patrones de lenguaje urgente, uso de imperativos, errores ortográficos.
    \item \textbf{Características estructurales:} presencia de URLs, número de enlaces, longitud del correo, HTML vs texto plano, uso de imágenes.
    \item \textbf{Características del remitente o metadatos:} dominio del remitente, coincidencia entre From y Return Path, IP de origen, registros SPF, DKIM y DMARC.
    \item \textbf{Características de la URL:} longitud, uso de subdominios, caracteres especiales, presencia de IP en lugar de dominio, similitud visual con dominios legítimos (homoglyphs).
    \item \textbf{Comportamiento y contexto:} tasa de envíos por remitente, patrones temporales, reputación del dominio.
\end{itemize}

\subsection{Problemas técnicos centrales}

\begin{itemize}
    \item \textbf{Desbalance de clases:} los correos legítimos suelen superar en número a los phishing; requiere técnicas de muestreo (oversampling,SMOTE), o métricas robustas (PR-AUC).
    \item \textbf{Drift y evolución de ataques:} campañas nuevas cambian vocabulario y tácticas; necesario reentrenamiento y monitorización.
    \item \textbf{Adversarialidad:} atacantes pueden adaptar textos para evadir detectores; conviene estudiar adversarial ML y robustez (\cite{b10}).
\end{itemize}
%========================
\section{Estado del Arte}

\subsection{Enfoques históricos y baselines}

\begin{itemize}
    \item \textbf{Reglas heurísticas y blacklists:} sistemas tempranos usaban listas negras de dominios, URLs y reglas de coincidencia de patrones; funcionan contra técnicas conocidas pero no contra evasiones.
    \item \textbf{Filtrado bayesiano y ML clásico:} Multinomial Naive Bayes y SVMs se convirtieron en baseline por su eficiencia y desempeño en datasets textuales (\cite{b1}, \cite{b2}).
\end{itemize}

\subsection{Métodos basados en características (features)}

\begin{itemize}
    \item Investigaciones tempranas mostraron que combinar features de contenido, URL y metadatos mejora la detección. \cite{b4} y \cite{b11} analizaron heurísticas de URL y contenido.
    \item Modelos de ensamblado (Random Forest, Gradient Boosting) demostraron robustez frente a ruido y capacidad para priorizar features relevantes (importancia de variables).
\end{itemize}

\subsection{Deep learning y representaciones modernas}

\begin{itemize}
    \item \textbf{CNN, RNN:} capturan patrones locales y secuencias, clasifican correos.
    \item \textbf{Transformers (BERT y variantes):} han mostrado mejoras marcadas en clasificación de texto y tareas de seguridad cuando se dispone de datos de calidad o se hace fine tuning (\cite{b8}).
    \item \textbf{Enfoques híbridos:} combinar embeddings BERT con features manuales (URL, encabezados) suele ser altamente efectivo, aprovecha semántica de texto y reglas estructurales.
\end{itemize}

\subsection{Datasets y benchmarks comunes}

\begin{itemize}
    \item \textbf{Enron Email Dataset:} corpus grande de correos empresariales (usado para spam o filtrado \cite{b12}).
    \item \textbf{SpamAssassin public corpus:} colección etiquetada de spam y ham \cite{b13}.
    \item \textbf{Phishing corpora y repositorios:} conjuntos públicos con muestras de phishing (\cite{b14} y \cite{b15}).
    \item Investigaciones recientes también construyen datasets a partir de correos reales anotados y de campañas de phishing actuales; calibrar modelos en datos recientes es crucial.
\end{itemize}

\subsection{Evaluación práctica y métricas}

\begin{itemize}
    \item \textbf{Recall prioritario:} en detección de phishing, disminuir falsos negativos suele ser más importante que minimizar falsos positivos.
    \item \textbf{PR-AUC vs ROC-AUC:} cuando la clase positiva es rara, PR-AUC refleja mejor la capacidad del clasificador para identificar positivos relevantes.
    \item \textbf{Explicabilidad y análisis de errores:} LIME, SHAP son herramientas para entender decisiones y depurar falsos positivos o negativos.
\end{itemize}

\subsection{Resumen de hallazgos empíricos}

\begin{itemize}
    \item Los modelos que combinan features manuales (URL, encabezados) con representaciones semánticas (embeddings o Transformers) tienden a obtener los mejores resultados.
    \item Random Forest y Gradient Boosting son fuertes competidores cuando los recursos son limitados; Transformers dominan cuando hay datos y cómputo suficientes.
    \item La robustez a nuevas campañas requiere pipelines de re-entrenamiento y detección de deriva.
\end{itemize}

%========================
\section{Metodología}
El sistema consta de los siguientes módulos:

\subsection{Vision General del pipeline}

El pipeline implementado tiene una serie de pasos reproducibles y modular, consta de las siguientes etapas:

\begin{enumerate}
    \item Adquisición y estandarización del dataset.
    \item Limpieza y normalización del texto.
    \item División del dataset en subconjuntos (train, validation y test) o uso de particiones ya provistas.
    \item Extracción de características textuales mediante TF-IDF (n-grams).
    \item Entrenamiento de modelos supervisados: Multinomial Naive Bayes (baseline), Logistic Regression (modelo lineal) y Random Forest (modelo de ensamblado).
    \item Evaluación detallada con métricas (precision, recall, F1-score, ROC-AUC, PR-AUC), análisis de la matriz de confusión y curvas ROC y PR.
    \item Interpretabilidad: análisis de coeficientes (LR) e importancia de features (RF).
    \item Persistencia de artefactos (vectorizador, modelos) y documentación de metadatos para reproducibilidad.
\end{enumerate}

\subsection{Dataset y particionado}

\subsubsection{Origen y formato}
El conjunto de datos principal es el archivo CSV preprocesado (en el notebook: \texttt{data/processed/all\_emails.csv} y los splits \texttt{data/processed/train.csv}, \texttt{val.csv}, \texttt{test.csv}). Cada fila contiene al menos las columnas: text (contenido del correo) y label ($0 =$ legítimo, $1 =$ phishing). Adicionalmente se mantiene una columna source para identificar la procedencia (\cite{b3}).

\subsubsection{Estandarización}
Se ejecuta una función \texttt{build\_standard\_dataframe(df, source\_name)} para homogeneizar nombres de columna, rellenar valores faltantes y asegurar el esquema text, label, source. Se eliminan entradas con text vacío y duplicados exactos (\texttt{subset=['text','label']}).

\subsubsection{Particionado}
El notebook utiliza un conjunto de splits cargados mediante \texttt{preprocessing.load\_splits()}. Si los splits no están provistos, la práctica estándar es dividir \texttt{all\_emails.csv} en \texttt{train/validation/test} con estratificación por etiqueta (stratify=y) para preservar la proporción de clases. 

\subsection{Preprocesamiento del texto}
Usaos para reducir el ruido y mejorar la calidad de las representaciones.

Se realiazonr las siguientes operaciones:

\begin{itemize}
    \item Eliminación de HTML y etiquetas: stripping de etiquetas <...> y contenido HTML residual.
    \item Normalización de espacios y caracteres: normalización Unicode, conversión a minúsculas, eliminación de saltos de línea y múltiples espacios.
    \item Sustitución de tokens estructurales: reemplazo de patrones por tokens especiales para evitar vocabulario explosivo:
    \begin{itemize}
        \item URLs → \texttt{<URL>}
        \item direcciones de correo → \texttt{<EMAIL>}
        \item números → \texttt{<NUM>}
    \end{itemize}
        \item Eliminación de caracteres no imprimibles y puntuación irrelevante (según criterios dependientes del idioma).
        \item Tokenización (implícita en el \texttt{TfidfVectorizer} de \textbf{\textit{scikit-learn}}) y stopword removal.
        \item Lematización y stemming : el notebook centraliza el preprocesamiento vía \texttt{preprocessing.py}.
\end{itemize}

\subsection{Extracción de características (vectorización)}

Se emplea 
\begin{minted}[
    linenos,
    fontsize=\small,
    frame=single,
    framesep=6pt,
    bgcolor=gray!5
]{python}
sklearn.feature_extraction.text.TfidfVectorizer
\end{minted}

para convertir textos a vectores numéricos esparcidos o sparse matrices. Los parámetros y decisiones principales son:

\begin{itemize}
    \item \texttt{ngram\_range=(1,2)}: unigramas y bigramas para capturar palabras sueltas y frases cortas como “verify account”.
    \item \texttt{max\_features=20000} : limitar el vocabulario para controlar dimensionalidad y ruido; ajustar según tamaño del corpus.
    \item \texttt{sublinear\_tf=True}: usar escala sublineal en la frecuencia ($1 + log(tf)$).
    \item \texttt{use\_idf=True}, \texttt{smooth\_idf=True}: comportamiento por defecto que favorece raras pero discriminativas palabras.
    \item \texttt{stop\_words='english'} o lista personalizada, según idioma del dataset.
    \item \texttt{norm='l2'}: normalización de vectores.
\end{itemize}

La salida después de la extracción de características es:

\begin{itemize}
    \item \textbf{Matrices dispersas}: \texttt{X\_train}, \texttt{X\_val} y \texttt{X\_test}
    \item \textbf{vectores} y\_$\star$
\end{itemize}

Que se guardan y se reusan para entrenamiento y despliegue. El vectorizados persiste en la línea:\\

%====== Code Listing 3
\begin{minted}[
    linenos,
    fontsize=\small,
    frame=single,
    framesep=6pt,
    bgcolor=gray!5
]{python}
joblib.dump('models/tfidf_vectorizer.pkl')
\end{minted}

\subsection{Modelos y configuración}

Se implementan tres modelos con los hiperparámetros usados en el notebook:

\subsubsection{Baseline Multinomial Naive Bayes}
\begin{itemize}
    \item \textbf{Clase}: \texttt{sklearn.naive\_bayes.MultinomialNB}
    \item \textbf{Hiperparámetro principal}: alpha=1.0 (Laplace smoothing) como valor por defecto.
    \item \textbf{Ventajas}: eficiente, rápido, buen baseline en tasks de texto.
    \item \textbf{Uso en notebook}: \texttt{baseline.py} contiene la función \texttt{train\_baseline()} que entrena y guarda el modelo.
\end{itemize}

\subsubsection{Logistic Regression (modelo lineal)}
\begin{itemize}
    \item \textbf{Clase}: \texttt{sklearn.linear\_model.LogisticRegression}
    \item \textbf{Parámetros usados}: \texttt{max\_iter=1000}, \texttt{random\_state=42}.
    \item \textbf{Interpretabilidad}: coeficientes asociados a features posibilitan identificar tokens que aumentan o disminuyen la probabilidad de phishing.
    \item \textbf{Notas}: \texttt{max\_iter} elevado para asegurar convergencia con vectores de alta dimensión.
\end{itemize}
\subsubsection{Random Forest}
\begin{itemize}
    \item \textbf{Clase}: \texttt{sklearn.ensemble.RandomForestClassifier}
    \item \textbf{Parámetros usados}: \texttt{n\_estimators=100}, \texttt{random\_state=42}, \texttt{n\_jobs=-1}.
    \item \textbf{Salida de interés}: \texttt{feature\_importances\_} para análisis de importancia de tokens.
    \item \textbf{Ventajas}: captura interacciones no lineales entre features, robusto ante ruido.
\end{itemize}

\subsection{Procedimiento de entrenamiento y validación}

\subsubsection{Entrenamiento reproducible}

\begin{enumerate}
    \item Cargar \texttt{X\_train}, \texttt{y\_train} y el vectorizador ya ajustado.
    \item Ajustar el modelo con \texttt{model.fit(X\_train, y\_train)}.
    \item Evaluar en \texttt{X\_val} y finalmente en \texttt{X\_test} (holdout) para estimación final.
\end{enumerate}
\subsubsection{Validación y tuning}

\begin{itemize}
    \item Para selección de hiperparámetros se recomienda \textbf{GridSearchCV} o \textbf{RandomizedSearchCV} sobre la partición de validación o mediante cross validation estratificada.
    \item Rango de búsqueda sugerido:
    \begin{itemize}
        \item Logistic Regression: \texttt{C = [0.01, 0.1, 1, 10]}, \texttt{penalty = ['l2']}.
        \item Random Forest: \texttt{n\_estimators = [100, 200, 500]}, \texttt{max\_depth = [None, 10, 50, 100]}, \texttt{min\_samples\_split = [2, 5, 10]}.
        \item Naive Bayes: \texttt{alpha = [0.1, 0.5, 1.0]}.
    \end{itemize}
\end{itemize}


\subsection{Descripción del Dataset}
Para el desarrollo y evaluación de los modelos propuestos, se utilizó el "Phishing Email Dataset" obtenido del repositorio de Kaggle (\cite{b3}).
Este conjunto de datos es una compilación robusta que integra múltiples fuentes de referencia en el ámbito de la ciberseguridad, incluyendo 
el corpus de Enron para correos corporativos legítimos, el dataset de SpamAssassin y colecciones de correos fraudulentos como el Nigerian Fraud y Nazario.

El dataset final consolidado consta de un total de 82,486 registros únicos. 
Una ventaja significativa de este recurso es su balance de clases, reduciendo el sesgo natural que suele existir en la detección de anomalías: 
contiene 42,891 correos etiquetados como phishing (aproximadamente el 52\%) y 39,595 correos legítimos (48\%). Los datos se presentan en dos columnas principales: 
\texttt{text\_combined}, que contiene la concatenación del asunto y el cuerpo del mensaje sin metadatos de cabecera complejos, y la etiqueta binaria \texttt{label} (0 para legítimo, 1 para phishing).

El autor solicitó hacer mención al artículo \textit{Novel Interpretable and Robust Web-based AI Platform for Phishing Email Detection} (\cite{b3}).  

\subsection{Modelos}

\begin{itemize}
    \item \textbf{Multinomial Naive Bayes:} \mintinline{python}{sklearn.naive_bayes.MultinomialNB(alpha=1.0)}
    \item \textbf{Random Forest:} \mintinline{python}{sklearn.ensemble.RandomForestClassifier} \mintinline{python}{(n_estimators=200, max_depth=None, n_jobs=-1, random_state=42)} usado para capturar interacciones entre tokens y es robusto a features ruidosos.
    \item \textbf{Validación:} 5-fold cross-validation y evaluación sobre test holdout (80/20). Se reportan métricas promedio y desviación estándar.
\end{itemize}

\subsection{Métricas de evaluación}

\begin{itemize}
    \item \textbf{Precision, Recall, F1-score:} para la clase positiva (phishing).
    \item \textbf{ROC-AUC y PR-AUC:} dado que la clase positiva puede ser minoritaria, PR-AUC es útil para valorar el rendimiento en detección.
    \item \textbf{Matriz de confusión:} análisis de falsos positivos y falsos negativos (importante por coste distinto de ambos errores).
\end{itemize}

%========================
\section{Resultados}
Para evaluar los resultados de los modelos entrenados usamos las siguientes métricas estándar para clasificación binaria:
\begin{itemize}
    \item \textbf{Accuracy:} Indica el porcentaje de emails correctamente clasificados
    \item \textbf{Precision:} Indica de los marcados como phishing, cuántos realmente lo son 
    \item \textbf{Recall:} Indica de todos los phishing reales, cuántos detectamos 
    \item \textbf{F1-Score:} Cálcula la media armónica entre Precision y Recall
    \item \textbf{Matriz de Confusión:} Detalla los errores por tipo
\end{itemize}
%=========

\subsection{Tabla comparativa de métricas}
\begin{table}[ht]
\centering
\caption{Comparación de métricas entre Logistic Regression y Random Forest}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Logistic Regression} & \textbf{Random Forest} \\ \hline
Accuracy  & 0.9830 & 0.9780 \\
Precision & 0.9823 & 0.9782 \\
Recall    & 0.9852 & 0.9751 \\
F1-Score  & 0.9850 & 0.9766 \\ \hline
\end{tabular}
\label{tab:comparacion-metricas}
\end{table}

%=========


\subsection{Matrices de confusión}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.4\textwidth]{imagenes/confusion_logistic_regression.png}
    \caption{Matriz de confusión del modelo Logistic Regression}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.4\textwidth]{imagenes/confusion_random_forest.png}
    \caption{Matriz de confusión del modelo Random Forest}
\end{figure}

%=========


%\subsection{Figuras}
% T O D O
%=========
%========================
\section{Discusión}
% T O D O
%=========

% \subsection{Comparación de Modelos}

% \begin{itemize}
%     \item \blindtext
% \end{itemize}

% \subsection{Preprocesamiento}

% \blindtext

% \subsection{Limitaciones}

% \blindtext

\subsection{Consideraciones Éticas}
% T O D O
%=========

\begin{itemize}
    \item El análisis de correos electrónicos implica acceso a información potencialmente sensible (mensajes privados, datos personales). Es obligatorio aplicar principios de minimización de datos, anonimización/pseudonimización y políticas de retención.
    \item La sobre-representación de ciertos idiomas puede traducirse en mayor tasa de falsos positivos para grupos específicos, siendo idiomas minoritarios, esto añade un sesgo en los datos de entrenamiento.
    \item Para tratar el sesgo en los datos se recomendaría evaluar métricas por subgrupos, usar muestreo estratificado y técnicas de debiasing.
    \item La aparición de falsos positivos puede bloquear comunicaciones legítimas y afectar operaciones como pérdida de informacióno demora. Ante esto se deberían aplicar políticas de cuarentena, notificaciones o vías de apelación, umbrales ajustables según el criterio del usuario u organización.
\end{itemize}

%========================
\section{Conclusiones}
%=========

\subsection{Conclusiones Principales}
\begin{enumerate}
    \item Logistic regression resulta ser más adecuado para resolver el problema de clasificación del proyecto: phishing vs no phishing
    \item El uso de stop words ayudó a evitar sesgos, sin embargo, se debió tener en consideración más palabras para esta lista
    \item Los predictores de phishing con mayor peso son: “account”, “money”, “click”, “replica”
    \item Los predictores de ligitimidad con mayor peso son: “thanks”, “opensuse”, “university”
\end{enumerate}
%=========


\subsection{Trabajo a Futuro}
\begin{enumerate}
    \item Añadir análisis de URLs embebidas
    \item Hacer entrenamiento y validación con datasets más modernos
    \item Implementar el modelo en aplicaciones o plugins de detección para sistemas de correo electrónico
\end{enumerate}
%=========

%========================
\begin{thebibliography}{00}

\bibitem{b1}
I.~Fette, N.~Sadeh, and A.~Tomasic,
``Learning to detect phishing emails,''
in \textit{Proceedings of the 16th International Conference on World Wide Web (WWW '07)},
Association for Computing Machinery, New York, NY, USA, 2007, pp.~649--656.
doi: \href{https://doi.org/10.1145/1242572.1242660}{10.1145/1242572.1242660}.

    \bibitem{b2}
S.~Abu-Nimeh, D.~Nappa, X.~Wang, and S.~Nair,
``A comparison of machine learning techniques for phishing detection,''
in \textit{Proceedings of the Anti-Phishing Working Groups 2nd Annual eCrime Researchers Summit (eCrime '07)},
Association for Computing Machinery, New York, NY, USA, 2007, pp.~60--69.
doi: \href{https://doi.org/10.1145/1299015.1299021}{10.1145/1299015.1299021}.

\bibitem{b3}
Naser Abdullah Alam. (2024). Phishing Email Dataset [Data set]. Kaggle. \url{https://doi.org/10.34740/KAGGLE/DS/5074342}

\bibitem{b4}
Garera, S., Provos, N., Chew, M., \& Rubin, A. D. (2007).
A framework for detection and measurement of phishing attacks.
En \textit{Proceedings of the 2007 ACM Workshop on Recurring Malcode (WORM '07)}
(pp. 1--8). Association for Computing Machinery.
\url{https://doi.org/10.1145/1314389.1314391}

\bibitem{b5}
Mikolov, T., Chen, K., Corrado, G., \& Dean, J. (2013).
\textit{Efficient estimation of word representations in vector space}.
arXiv preprint arXiv:1301.3781.
\url{https://arxiv.org/abs/1301.3781}

\bibitem{b6}
Pennington, J., Socher, R., \& Manning, C. D. (2014).
GloVe: Global vectors for word representation.
En Moschitti, A., Pang, B., \& Daelemans, W. (Eds.),
\textit{Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)}
(pp. 1532--1543). Association for Computational Linguistics.
\url{https://aclanthology.org/D14-1162/}

\bibitem{b7}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \& Polosukhin, I. (2023).
\textit{Attention is all you need}.
arXiv preprint arXiv:1706.03762.
\url{https://arxiv.org/abs/1706.03762}

\bibitem{b8}
Devlin, J., Chang, M.-W., Lee, K., \& Toutanova, K. (2019).
\textit{BERT: Pre-training of deep bidirectional transformers for language understanding}.
arXiv preprint arXiv:1810.04805.
\url{https://arxiv.org/abs/1810.04805}


\bibitem{b9}
Manning, C. D., Raghavan, P., \& Schütze, H. (2009). Introduction to Information Retrieval (Online edition). Cambridge University Press. Disponible en \href{https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf}{PDF}


\bibitem{b10}
Biggio, B., \& Roli, F. (2018).
Wild patterns: Ten years after the rise of adversarial machine learning.
\textit{Pattern Recognition, 84}, 317--331.
\url{https://doi.org/10.1016/j.patcog.2018.07.023}

\bibitem{b11}
Bergholz, A., De Beer, J., Glahn, S., Moens, M.-F., Paa\ss{}, G., \& Strobel, S. (2010).
New filtering approaches for phishing email.
\textit{Journal of Computer Security, 18}(1), 7--35.

\bibitem{b12}
Enron Corp y Cohen, W. W. (2015). \textit{Conjunto de datos de correos electrónicos de Enron}. Comisión Reguladora Federal de Energía de los Estados Unidos, comp. [Filadelfia, PA: William W. Cohen, MLD, CMU]. Recurso electrónico. Recuperado de \url{https://www.loc.gov/item/2018487913/}

\bibitem{b13}
Beato, A. (s.f.). \textit{SpamAssassin Public Corpus}. Kaggle. \url{https://www.kaggle.com/datasets/beatoa/spamassassin-public-corpus} (Corpus público de SpamAssassin del proyecto Apache).

\bibitem{b14}
PhishTank. (s.f.). \emph{Join the fight against phishing}. Recuperado de \url{https://www.phishtank.com/}


\bibitem{b15}
R. Sood, \emph{Phishing email dataset Nazario\_5 and TREC07}. Kaggle, 2023. [En línea]. Disponible: \url{https://www.kaggle.com/datasets/rohansood98/phishing-email-dataset-nazario-5-and-trec07}

%============================



% \bibitem{b5}
% Mitchell, T. M. (1997). \textit{Machine learning}. McGraw-Hill Science/Engineering/Math.

% \bibitem{b6}
% Han, J., Kamber, M., \& Pei, J. (2011).
% \textit{Data mining: Concepts and techniques} (3rd ed.).
% Recuperado de \url{https://www.scholartext.com/book/88809627?_locale=fr}

% \bibitem{b7}
% Jurafsky, D., \& Martin, J. H. (2009).
% \textit{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}.
% Prentice Hall.

% \bibitem{b8}
% Goodfellow, I., Bengio, Y., \& Courville, A. (2016).
% \textit{Deep learning}. MIT Press.
% Recuperado de \url{http://www.deeplearningbook.org}








% \bibitem{b13}
% Goodfellow, I. J., Shlens, J., \& Szegedy, C. (2015).
% \textit{Explaining and harnessing adversarial examples}.
% arXiv preprint arXiv:1412.6572.
% \url{https://arxiv.org/abs/1412.6572}

% \bibitem{b14}
% Lundberg, S., \& Lee, S.-I. (2017).
% \textit{A unified approach to interpreting model predictions}.
% arXiv preprint arXiv:1705.07874.
% \url{https://arxiv.org/abs/1705.07874}




% \bibitem{b17}
% Ribeiro, M. T., Singh, S., \& Guestrin, C. (2016).
% \textit{"Why should I trust you?": Explaining the predictions of any classifier}.
% arXiv preprint arXiv:1602.04938.
% \url{https://arxiv.org/abs/1602.04938}



% \bibitem{b19}
% European Parliament and Council. (2016).
% Regulation (EU) 2016/679 (General Data Protection Regulation).
% \textit{Official Journal of the European Union}.

% \bibitem{b20}
% Elhoseny, M., Abdel-Salam, M., Khafaga, D. S., Aldakheel, E. A., \& El-Hasnony, I. M. (2025). Robust Optimized Deep Learning-Based Phishing Detection Framework for semantic web systems using boosted triangular topology aggregation optimization. International Journal on Semantic Web and Information Systems, 21(1), 1-58. \url{https://doi.org/10.4018/ijswis.388181}

% \bibitem{b21}
% Naser Abdullah Alam. (2024). Phishing Email Dataset [Data set]. Kaggle. \url{https://doi.org/10.34740/KAGGLE/DS/5074342}

\end{thebibliography}

% \section*{Anexos}

% \begin{itemize}
%     \item \textbf{Anexo A:} Código (notebook Colab) con pipeline completo (preprocesamiento, vectorización, entrenamiento y evaluación).
%     \item \textbf{Anexo B:} Parámetros exactos de los modelos y resultados de las 5 corridas cross-validation (media y desviación estándar).
%     \item \textbf{Anexo C:} Plots (Figura 1, Figura 2, Figura 3) y matrices de confusión.
%     \item \textbf{Anexo D:} Tabla detallada de distribución de trabajo y cronograma (según requisitos del curso).
% \end{itemize}


\end{document}
% %====== Code Listing 1
% \begin{listing}[H]
%     \begin{minted}[
%         bgcolor=gray!10,
%         fontsize=\small,
%         linenos,
%         numbersep=5pt,
%         frame=lines,
%         framesep=10pt]
%         {python}
%     def fibonacci(n):
%         if n <= 1:
%             return n
%         return fibonacci(n-1) + fibonacci(n-2)
%     \end{minted}
% \caption{Elegant Fibonacci in Python with subtle background and line numbers.}
% \label{lst:fib}
% \end{listing}
% %====== Code Listing 2
% \begin{minted}[linenos]{python}
%   for i in range(0,2):
%       print(i)
% \end{minted}
% %====== Code Listing 3
% \begin{minted}[
%     linenos,
%     fontsize=\small,
%     frame=single,
%     framesep=6pt,
%     bgcolor=gray!5
% ]{python}
% joblib.dump('models/tfidf_vectorizer.pkl')
% \end{minted}